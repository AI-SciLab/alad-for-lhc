{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.rcParams['text.usetex'] = True\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from alad_mod.alad import ALAD\n",
    "from evaluation.histogram_builder import *\n",
    "from data.hlf_preprocessing import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "loading alad\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\nW1116 09:59:05.901792 140574736594752 lazy_loader.py:50] \nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\n",
      "W1116 09:59:05.954838 140574736594752 deprecation_wrapper.py:119] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:29: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\n",
      "W1116 09:59:05.958526 140574736594752 deprecation_wrapper.py:119] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:44: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n\n",
      "W1116 09:59:05.961282 140574736594752 deprecation.py:323] From /home/oliverkn/pro/alad_6021/2_l16/config.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.dense instead.\n",
      "W1116 09:59:06.358453 140574736594752 deprecation.py:323] From /home/oliverkn/pro/alad_6021/2_l16/config.py:168: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W1116 09:59:06.477331 140574736594752 deprecation.py:323] From /home/oliverkn/pro/alad_6021/2_l16/config.py:176: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.dropout instead.\n",
      "W1116 09:59:06.820434 140574736594752 deprecation.py:323] From /home/oliverkn/pro/pycharm/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1116 09:59:06.902833 140574736594752 deprecation_wrapper.py:119] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:126: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n\n",
      "W1116 09:59:06.903702 140574736594752 deprecation_wrapper.py:119] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:133: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n\n",
      "W1116 09:59:06.904328 140574736594752 deprecation_wrapper.py:119] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:133: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\n",
      "W1116 09:59:06.904956 140574736594752 deprecation_wrapper.py:119] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:143: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n\n",
      "W1116 09:59:09.414456 140574736594752 deprecation.py:323] From /home/oliverkn/pro/pycharm/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1116 09:59:10.129636 140574736594752 deprecation.py:323] From /home/oliverkn/pro/pycharm/venv/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.flatten instead.\n",
      "W1116 09:59:10.341709 140574736594752 deprecation.py:506] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:214: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\nInstructions for updating:\nkeep_dims is deprecated, use keepdims instead\n",
      "W1116 09:59:10.379467 140574736594752 deprecation_wrapper.py:119] From /home/oliverkn/cloud/eth/2019_FS/pro/pycharm/alad_mod/alad.py:429: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\n",
      "W1116 09:59:10.483641 140574736594752 deprecation.py:323] From /home/oliverkn/pro/pycharm/venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "result_path = '/home/oliverkn/pro/alad_6021/2_l16'\n",
    "model_file = 'model-10000000'\n",
    "\n",
    "print('loading alad')\n",
    "\n",
    "# loading config\n",
    "spec = importlib.util.spec_from_file_location('config', os.path.join(result_path, 'config.py'))\n",
    "config_alad = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(config_alad)\n",
    "\n",
    "# loading preprocessor\n",
    "preprocessor = load(os.path.join(result_path, 'preprocessor.pkl'))\n",
    "\n",
    "# loading alad\n",
    "tf.reset_default_graph()\n",
    "ad = ALAD(config_alad, tf.Session())\n",
    "ad.load(os.path.join(result_path, model_file))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load ALAD\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "thres = 30\n",
    "\n",
    "score_type = 'l1'\n",
    "\n",
    "cont_bins = 40\n",
    "hist_settings = {}\n",
    "hist_settings['HT'] = {'symbol': '$H_T$ [GeV]', 'range': (0, 3000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['mass_jet'] = {'symbol': '$M_J$ [GeV]', 'range': (0, 3000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_jet'] = {'symbol': '$N_J$', 'range': (0, 15), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['n_bjet'] = {'symbol': '$N_b$', 'range': (0, 15), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['lep_pt'] = {'range': (20, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_eta'] = {'range': (-2.5, 2.5), 'yscale': 'linear', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_charge'] = {'range': (-1, 1), 'yscale': 'linear', 'int': True}\n",
    "hist_settings['lep_iso_ch'] = {'range': (0, 0.1), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_iso_neu'] = {'range': (0, 0.1), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_iso_gamma'] = {'range': (0, 0.1), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['MET'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['METo'] = {'range': (-100, 100), 'yscale': 'linear', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['METp'] = {'range': (-100, 100), 'yscale': 'linear', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['MT'] = {'range': (0, 200), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_mu'] = {'range': (0, 15), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['pt_mu'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['mass_mu'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_ele'] = {'range': (0, 15), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['pt_ele'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['mass_ele'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_neu'] = {'range': (0, 400), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['n_ch'] = {'range': (0, 1000), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['n_photon'] = {'range': (0, 1000), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "\n",
    "def pre_select(x):\n",
    "    filter_iso = x[:,7] + x[:,8] + x[:,9] < 0.1\n",
    "    filter_eta = np.abs(x[:,5]) < 1.4\n",
    "    # filter_eta2 = np.logical_or(np.abs(x[:,5]) < 1.44, np.abs(x[:,5]) > 1.56)\n",
    "    filter_njets = x[:,2] > 1\n",
    "    # filter_idx = filter_njets * filter_eta * filter_iso #* filter_eta2\n",
    "    filter_idx = filter_iso * filter_eta * filter_njets\n",
    "    \n",
    "    return x[filter_idx]\n",
    "\n",
    "def anomaly_select(x):\n",
    "    x_transformed = preprocessor.transform(x)\n",
    "    scores = ad.get_anomaly_scores(x_transformed, type=score_type)\n",
    "    anomaly_idx = scores > thres\n",
    "    return x[anomaly_idx]\n",
    "\n",
    "def post_select(x):\n",
    "    filter_bjets =  x[:,3] > 1\n",
    "    filter_idx = filter_bjets \n",
    "    \n",
    "    return x[filter_idx]\n",
    "\n",
    "def build_hists(x, n_max, batch_size=2 ** 20):\n",
    "    builder_raw = HistogramBuilder(hist_settings)\n",
    "    builder_pre = HistogramBuilder(hist_settings)\n",
    "    builder_ano= HistogramBuilder(hist_settings)\n",
    "    builder_pos = HistogramBuilder(hist_settings)\n",
    "\n",
    "    n = x.shape[0]\n",
    "    n = min(n, n_max)\n",
    "    n_batches = int(n / batch_size) + 1\n",
    "    \n",
    "    for t in range(n_batches):\n",
    "        print('batch number ' + str(t))\n",
    "        ran_from = int(t * batch_size)\n",
    "        ran_to = (t + 1) * batch_size\n",
    "        ran_to = int(np.clip(ran_to, 0, n))\n",
    "        x_raw = x[ran_from:ran_to]\n",
    "        \n",
    "        # raw\n",
    "        builder_raw.add_data(x_raw)\n",
    "        \n",
    "        # pre selection\n",
    "        x_pre = pre_select(x_raw)\n",
    "        builder_pre.add_data(x_pre)\n",
    "        \n",
    "        # anomaly selection\n",
    "        x_ano = anomaly_select(x_pre)\n",
    "        builder_ano.add_data(x_ano)\n",
    "        \n",
    "        # post selection\n",
    "        x_pos = post_select(x_pre)\n",
    "        builder_pos.add_data(x_pos)\n",
    "        \n",
    "    return builder_raw.get_histogram_data(), builder_pre.get_histogram_data(),\\\n",
    "           builder_ano.get_histogram_data(), builder_pos.get_histogram_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "------------------------------building dy1jets\nbatch number 0\n",
      "93 / 907244 = 102_ppm\nprocessed/available: 907244/907244 = 1.000000\nN_tot=3164044, N_target=3056142, w=0.965898\n------------------------------building dy2jets\nbatch number 0\n",
      "51 / 308661 = 165_ppm\nprocessed/available: 308661/308661 = 1.000000\nN_tot=1030072, N_target=986028, w=0.957242\n------------------------------building dy3jets\nbatch number 0\n",
      "253 / 647464 = 390_ppm\nprocessed/available: 647464/647464 = 1.000000\nN_tot=2100961, N_target=277831, w=0.132240\n------------------------------building dy4jets\nbatch number 0\n",
      "723 / 521818 = 1385_ppm\nprocessed/available: 521818/521818 = 1.000000\nN_tot=1643501, N_target=81715, w=0.049720\n------------------------------building w1jets\nbatch number 0\n",
      "batch number 1\n",
      "batch number 2\n",
      "batch number 3\n",
      "143 / 3413855 =  41_ppm\nprocessed/available: 3413855/3413855 = 1.000000\nN_tot=16921485, N_target=24405561, w=1.442282\n------------------------------building w2jets\nbatch number 0\n",
      "batch number 1\n",
      "180 / 1667510 = 107_ppm\nprocessed/available: 1667510/1667510 = 1.000000\nN_tot=7930663, N_target=7817406, w=0.985719\n------------------------------building w3jets\nbatch number 0\n",
      "72 / 361756 = 199_ppm\nprocessed/available: 361756/361756 = 1.000000\nN_tot=1693401, N_target=1656091, w=0.977968\n------------------------------building ttbar\nbatch number 0\n",
      "batch number 1\n",
      "batch number 2\n",
      "batch number 3\n",
      "10798 / 4148758 = 2602_ppm\nprocessed/available: 4148758/4148758 = 1.000000\nN_tot=23961545, N_target=1205750, w=0.050320\n------------------------------building data\nbatch number 0\n",
      "batch number 1\n",
      "batch number 2\n",
      "batch number 3\n",
      "batch number 4\n",
      "batch number 5\n",
      "batch number 6\n",
      "batch number 7\n",
      "batch number 8\n",
      "batch number 9\n",
      "batch number 10\n",
      "batch number 11\n",
      "batch number 12\n",
      "batch number 13\n",
      "batch number 14\n",
      "batch number 15\n",
      "batch number 16\n",
      "batch number 17\n",
      "batch number 18\n",
      "batch number 19\n",
      "batch number 20\n",
      "batch number 21\n",
      "batch number 22\n",
      "batch number 23\n",
      "batch number 24\n",
      "batch number 25\n",
      "batch number 26\n",
      "batch number 27\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n_max = int(1000e5)\n",
    "\n",
    "# data\n",
    "lum = 4429.0 #* 1.164090\n",
    "\n",
    "sets = {}\n",
    "sets['dy1jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7719/data.hdf5', 'xsec':561, 'K':1.23}\n",
    "sets['dy2jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7721/data.hdf5', 'xsec':181, 'K':1.23}\n",
    "sets['dy3jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7722/data.hdf5', 'xsec':51, 'K':1.23}\n",
    "sets['dy4jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7723/data.hdf5', 'xsec':15, 'K':1.23}\n",
    "\n",
    "sets['w1jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9863/data.hdf5', 'xsec':4480, 'K':1.23}\n",
    "sets['w2jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9864/data.hdf5', 'xsec':1435, 'K':1.23}\n",
    "sets['w3jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9865/data.hdf5', 'xsec':304, 'K':1.23}\n",
    "\n",
    "# sets['dy1jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7730/data.hdf5', 'xsec':1141, 'K':1}\n",
    "# sets['dy2jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7723/data.hdf5', 'xsec':0, 'K':1.23}\n",
    "# sets['dy3jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7723/data.hdf5', 'xsec':0, 'K':1.23}\n",
    "# sets['dy4jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7723/data.hdf5', 'xsec':0, 'K':1.23}\n",
    "# \n",
    "# sets['w1jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9938/data.hdf5', 'xsec':5090, 'K':1}\n",
    "# sets['w2jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9940/data.hdf5', 'xsec':7110, 'K':1}\n",
    "# sets['w3jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9865/data.hdf5', 'xsec':0, 'K':1}\n",
    "\n",
    "sets['ttbar'] = {'file': '/home/oliverkn/pro/opendata_v2/9588/data.hdf5', 'xsec':164, 'K':1.66}\n",
    "\n",
    "sets['data'] = {'file': '/home/oliverkn/pro/opendata_v2/6021/data.hdf5', 'xsec':1, 'K':1}\n",
    "\n",
    "\n",
    "for key, set in sets.items():\n",
    "    # if key == 'data':\n",
    "    #     continue\n",
    "    \n",
    "    print('------------------------------building ' + key)\n",
    "    \n",
    "    # load data\n",
    "    file = set['file']\n",
    "    h5file = h5py.File(file, 'r')\n",
    "    x = h5file['data']\n",
    "    \n",
    "    if key == 'data':\n",
    "        N_tot = lum\n",
    "    else:\n",
    "        N_tot = h5file['n_tot'][()]\n",
    "    \n",
    "    # build hists\n",
    "    hist_raw, hist_pre, hist_ano, hist_pos = build_hists(x, n_max=n_max)\n",
    "    \n",
    "    n_events = hist_raw['HT'].n\n",
    "    n_events_a = hist_ano['HT'].n\n",
    "    print('%d / %d = %3d_ppm' % (n_events_a, n_events, (n_events_a / n_events*1e6)))\n",
    "    \n",
    "    # weight\n",
    "    fraction_processed = n_events/x.shape[0]\n",
    "    print('processed/available: %d/%d = %f'%(n_events, x.shape[0], fraction_processed))\n",
    "    \n",
    "    N_target = lum * set['K'] * set['xsec']\n",
    "    weight =  N_target / (N_tot * fraction_processed)\n",
    "    print('N_tot=%d, N_target=%d, w=%f'%(N_tot, N_target, weight))\n",
    "    \n",
    "    # scaling up hists\n",
    "    hist_raw = scale_hists(hist_raw, weight)\n",
    "    hist_pre = scale_hists(hist_pre, weight)\n",
    "    hist_ano = scale_hists(hist_ano, weight)\n",
    "    hist_pos = scale_hists(hist_pos, weight)\n",
    "    \n",
    "    set['hist_raw'] = hist_raw\n",
    "    set['hist_pre'] = hist_pre\n",
    "    set['hist_ano'] = hist_ano\n",
    "    set['hist_pos'] = hist_pos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% compute hist\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum_n = 0\n",
    "for key in ['w1jets', 'w2jets', 'w3jets', 'dy1jets', 'dy2jets', 'dy3jets', 'dy4jets', 'ttbar']:\n",
    "    n = sets[key]['hist_raw']['HT'].n\n",
    "    sum_n += n\n",
    "    \n",
    "for key in ['w1jets', 'w2jets', 'w3jets', 'dy1jets', 'dy2jets', 'dy3jets', 'dy4jets', 'ttbar']:\n",
    "    n = sets[key]['hist_raw']['HT'].n\n",
    "    print('%s: %d (%f)'%(key, n, n/sum_n))\n",
    "\n",
    "print('--------------------------------------')\n",
    "print('n_tup (mc):   %d' % sum_n)\n",
    "print('n_tup (data): %d' % sets['data']['hist_raw']['HT'].n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% confirm normalization\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_proc_list = ['w1jets', 'w2jets', 'w3jets']\n",
    "DY_proc_list = ['dy1jets', 'dy2jets', 'dy3jets', 'dy4jets']\n",
    "ttbar_proc_list = ['ttbar']\n",
    "data_proc_list = ['data']\n",
    "\n",
    "b_proc_list = W_proc_list + DY_proc_list\n",
    "bs_proc_list = b_proc_list + ttbar_proc_list\n",
    "proc_list = bs_proc_list + data_proc_list\n",
    "\n",
    "# hist_cut_proc_dict[cut][proc]\n",
    "hist_cut_proc_dict = {}\n",
    "for cut in ['hist_raw', 'hist_pre', 'hist_ano','hist_pos']:\n",
    "    hist_proc_dict = {}\n",
    "    for proc in proc_list:\n",
    "        hist_proc_dict[proc] = sets[proc][cut]\n",
    "    hist_cut_proc_dict[cut]=hist_proc_dict\n",
    "    \n",
    "# sum sub processes W, DY, background, background + signal\n",
    "for cut in ['hist_raw', 'hist_pre', 'hist_ano', 'hist_pos']:\n",
    "    hist_proc_dict = hist_cut_proc_dict[cut]\n",
    "    \n",
    "    # sum W\n",
    "    hist_W = sum_hists([hist_proc_dict[proc] for proc in W_proc_list])\n",
    "    hist_proc_dict['W'] = hist_W\n",
    "    \n",
    "    # sum DY\n",
    "    hist_DY = sum_hists([hist_proc_dict[proc] for proc in DY_proc_list])\n",
    "    hist_proc_dict['DY'] = hist_DY\n",
    "    \n",
    "    #sum background\n",
    "    hist_b = sum_hists([hist_proc_dict[proc] for proc in b_proc_list])\n",
    "    hist_proc_dict['b'] = hist_b\n",
    "    \n",
    "    #sum background + signal\n",
    "    hist_bs = sum_hists([hist_proc_dict[proc] for proc in bs_proc_list])\n",
    "    hist_proc_dict['bs'] = hist_bs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% reshape hist dicts\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# amp = trans_data / trans_mc = (n_data_a / n_data) / (n_mc_a / n_mc)\n",
    "\n",
    "hist_mc_b = hist_cut_proc_dict['hist_ano']['b'] # background (W, DY)\n",
    "hist_mc_bs = hist_cut_proc_dict['hist_ano']['bs'] # background + ttbar\n",
    "\n",
    "def compute_amp(hist_pre, hist_ano):\n",
    "    hist_amp = {}\n",
    "\n",
    "    for key in hist_pre.keys():\n",
    "        hist_amp[key] = Histogram(hist_pre[key].bin_edges)\n",
    "        hist_amp[key].bin_content = hist_ano[key].bin_content / (hist_pre[key].bin_content+1)\n",
    "    \n",
    "    return hist_amp\n",
    "\n",
    "# hist_amp_dict[proc]\n",
    "hist_amp_dict = {}\n",
    "hist_amp_dict['b'] = compute_amp(hist_cut_proc_dict['hist_pre']['b'], hist_cut_proc_dict['hist_ano']['b'])\n",
    "hist_amp_dict['bs'] = compute_amp(hist_cut_proc_dict['hist_pre']['bs'], hist_cut_proc_dict['hist_ano']['bs'])\n",
    "hist_amp_dict['data'] = compute_amp(hist_cut_proc_dict['hist_pre']['data'], hist_cut_proc_dict['hist_ano']['data'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% compute ADSE (anomaly detector selection efficiency)\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_list = ['HT', 'mass_jet', 'n_jet', 'n_bjet']\n",
    "background_plot_list = ['W', 'DY', 'ttbar']\n",
    "\n",
    "plot_size = 5\n",
    "\n",
    "color_dict = {}\n",
    "color_dict['W']='tab:blue'\n",
    "color_dict['DY']='tab:green'\n",
    "color_dict['ttbar']='tab:red'\n",
    "color_dict['data']='tab:purple'\n",
    "\n",
    "label_dict = {}\n",
    "label_dict['W'] = r'$W \\rightarrow \\mu\\nu$'\n",
    "label_dict['DY'] = r'$Z/\\gamma^* \\rightarrow ll$'\n",
    "label_dict['ttbar'] = r'$t\\bar{t}$'\n",
    "\n",
    "all_lin = False\n",
    "\n",
    "n_features = len(feature_list)\n",
    "fig, ax_arr = plt.subplots(n_features, 4, figsize=(4 * plot_size, n_features * plot_size))\n",
    "\n",
    "for row, feature in enumerate(feature_list):\n",
    "    f_setting = hist_settings[feature]\n",
    "    \n",
    "    # col 0, 1\n",
    "    for col, cut in enumerate(['hist_pre', 'hist_ano']):\n",
    "        ax = ax_arr[row, col]\n",
    "    \n",
    "        # plot background stacked\n",
    "        x_list = []\n",
    "        bin_edges = None\n",
    "        weights_list = []\n",
    "        color_list = []\n",
    "        label_list = []\n",
    "        \n",
    "        for proc in background_plot_list:\n",
    "            hist = hist_cut_proc_dict[cut][proc]\n",
    "            bin_edges = hist[feature].bin_edges\n",
    "            x_list.append(hist[feature].bin_edges[:-1])\n",
    "            weights_list.append(hist[feature].bin_content)\n",
    "            color_list.append(color_dict[proc])\n",
    "            label_list.append(label_dict[proc])\n",
    "            \n",
    "        ax.hist(x_list, bin_edges, weights=weights_list, \n",
    "                stacked=True, histtype='stepfilled', color=color_list, label=label_list)\n",
    "        \n",
    "        # axis settings\n",
    "        if all_lin is False:\n",
    "            ax.set_yscale(f_setting['yscale'])\n",
    "            \n",
    "        ax.set_xlabel(f_setting['symbol'])\n",
    "\n",
    "    # col 2\n",
    "    ax = ax_arr[row, 2]\n",
    "    \n",
    "    # plot data\n",
    "    hist_data_f = hist_cut_proc_dict['hist_pre']['data'][feature]\n",
    "    bin_edges = hist_data_f.bin_edges\n",
    "    bin_content = hist_data_f.bin_content\n",
    "    ax.hist(bin_edges[:-1], bin_edges, weights=bin_content, histtype='stepfilled', density=True,color=color_dict['data'], label='data')\n",
    "    \n",
    "    # plot data anomalous\n",
    "    hist_data_f = hist_cut_proc_dict['hist_ano']['data'][feature]\n",
    "    bin_edges = hist_data_f.bin_edges\n",
    "    bin_content = hist_data_f.bin_content\n",
    "    ax.hist(bin_edges[:-1], bin_edges, weights=bin_content, histtype='step', color='b', label='data a', density=True)\n",
    "\n",
    "    # axis settings\n",
    "    if all_lin is False:\n",
    "        ax.set_yscale(f_setting['yscale'])\n",
    "\n",
    "# fix ppm\n",
    "# uncertainty (opt)\n",
    "\n",
    "# plot ADSE\n",
    "for row, feature in enumerate(feature_list):\n",
    "    ax = ax_arr[row, 3]\n",
    "    f_setting = hist_settings[feature]\n",
    "    \n",
    "    bin_edges = hist_amp_dict['b'][feature].bin_edges\n",
    "    bin_content = hist_amp_dict['b'][feature].bin_content\n",
    "    ax.hist(bin_edges[:-1], bin_edges, weights = bin_content, histtype='stepfilled',# density=True,\n",
    "            label='background', color='blue')\n",
    "\n",
    "    bin_edges = hist_amp_dict['bs'][feature].bin_edges\n",
    "    bin_content = hist_amp_dict['bs'][feature].bin_content\n",
    "    ax.hist(bin_edges[:-1], bin_edges, weights = bin_content, histtype='step',# density=True,\n",
    "            label='W+DY+tt', color='red')\n",
    "    \n",
    "    # bin_edges = hist_amp_dict['data'][feature].bin_edges\n",
    "    # bin_content = hist_amp_dict['data'][feature].bin_content\n",
    "    # ax.hist(bin_edges[:-1], bin_edges, weights = bin_content, histtype='step',# density=True,\n",
    "    #         label='W+DY+tt', color='magenta')\n",
    "\n",
    "    bin_edges = hist_amp_dict['data'][feature].bin_edges\n",
    "    bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\n",
    "    bin_content = hist_amp_dict['data'][feature].bin_content\n",
    "    ax.plot(bin_centers, bin_content, 'bo', label='data')\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "\n",
    "handles, labels = ax_arr[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc = 'upper center', ncol=4)\n",
    "# fig.legend(handles, labels, ncol=4, bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "#         mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "\n",
    "# plt.savefig('figures/adse.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% # ms stack vs data (after pre), ...(after ano), (amp)\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plots\n",
    "# mc detailed no stack\n",
    "\n",
    "# data vs mc (after cuts)\n",
    "\n",
    "# data_a vs mc_a (with ppm fixed) (with ad trained on clean mc)\n",
    "\n",
    "# amplification \n",
    "\n",
    "# normal and anomalous b=0,1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}