{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from uncertainties import unumpy, ufloat\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from alad_mod.alad import ALAD\n",
    "from core.histogram_builder import *\n",
    "from data.hlf_preprocessing import load"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alad\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:29: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:44: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From model/config.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/oliverkn/pro/pycharm/pycharm/venv37/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From model/config.py:168: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From model/config.py:176: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/oliverkn/pro/pycharm/pycharm/venv37/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:126: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:133: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:133: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:143: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/oliverkn/pro/pycharm/pycharm/venv37/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/oliverkn/pro/pycharm/pycharm/venv37/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:214: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/oliverkn/cloud/eth/2019_FS/pro/publication/alad-for-lhc/alad_mod/alad.py:421: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from model/model-10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliverkn/pro/pycharm/pycharm/venv37/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/oliverkn/pro/pycharm/pycharm/venv37/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RobustScaler from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/oliverkn/pro/pycharm/pycharm/venv37/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "result_path = 'model/'\n",
    "model_file = 'model-10000000'\n",
    "\n",
    "print('loading alad')\n",
    "\n",
    "# loading config\n",
    "spec = importlib.util.spec_from_file_location('config', os.path.join(result_path, 'config.py'))\n",
    "config_alad = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(config_alad)\n",
    "\n",
    "# loading preprocessor\n",
    "preprocessor = load(os.path.join(result_path, 'preprocessor.pkl'))\n",
    "\n",
    "# loading alad\n",
    "tf.reset_default_graph()\n",
    "ad = ALAD(config_alad, tf.Session())\n",
    "ad.load(os.path.join(result_path, model_file))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load ALAD\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "lum = 4429\n",
    "\n",
    "W_proc_list = ['w1jets', 'w2jets', 'w3jets']\n",
    "DY_proc_list = ['dy1jets', 'dy2jets', 'dy3jets', 'dy4jets']\n",
    "ttbar_proc_list = ['ttbar']\n",
    "data_proc_list = ['data']\n",
    "b_proc_list = W_proc_list + DY_proc_list\n",
    "bs_proc_list = b_proc_list + ttbar_proc_list\n",
    "proc_list = bs_proc_list + data_proc_list\n",
    "\n",
    "sets = {}\n",
    "sets['dy1jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7719/data_pre.hdf5', 'xsec':561, 'K':1.23}\n",
    "sets['dy2jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7721/data_pre.hdf5', 'xsec':181, 'K':1.23}\n",
    "sets['dy3jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7722/data_pre.hdf5', 'xsec':51, 'K':1.23}\n",
    "sets['dy4jets'] = {'file': '/home/oliverkn/pro/opendata_v2/7723/data_pre.hdf5', 'xsec':15, 'K':1.23}\n",
    "\n",
    "sets['w1jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9863/data_pre.hdf5', 'xsec':4480, 'K':1.23}\n",
    "sets['w2jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9864/data_pre.hdf5', 'xsec':1435, 'K':1.23}\n",
    "sets['w3jets'] = {'file': '/home/oliverkn/pro/opendata_v2/9865/data_pre.hdf5', 'xsec':304, 'K':1.23}\n",
    "\n",
    "sets['ttbar'] = {'file': '/home/oliverkn/pro/opendata_v2/9588/data_pre.hdf5', 'xsec':164, 'K':1.66}\n",
    "sets['data'] = {'file': '/home/oliverkn/pro/opendata_v2/6021/data_pre.hdf5', 'xsec':1, 'K':1}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% sample description\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------loading dy1jets-----------------\n",
      "n_tup        = 418047\n",
      "n_tup_target = 403790\n",
      "-----------------loading dy2jets-----------------\n",
      "n_tup        = 154836\n",
      "n_tup_target = 148215\n",
      "-----------------loading dy3jets-----------------\n",
      "n_tup        = 333484\n",
      "n_tup_target = 44099\n",
      "-----------------loading dy4jets-----------------\n",
      "n_tup        = 267980\n",
      "n_tup_target = 13323\n",
      "-----------------loading w1jets-----------------\n",
      "n_tup        = 2053589\n",
      "n_tup_target = 1682703\n",
      "-----------------loading w2jets-----------------\n",
      "n_tup        = 715775\n",
      "n_tup_target = 705553\n",
      "-----------------loading w3jets-----------------\n",
      "n_tup        = 171661\n",
      "n_tup_target = 167878\n",
      "-----------------loading ttbar-----------------\n",
      "n_tup        = 2552906\n",
      "n_tup_target = 128462\n",
      "-----------------loading data-----------------\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "def pre_select(x):\n",
    "    filter_iso = x[:,7] + x[:,8] + x[:,9] < 0.1\n",
    "    filter_eta = np.abs(x[:,5]) < 1.4\n",
    "    filter_njets = x[:,2] > 1\n",
    "    filter_idx = filter_iso * filter_eta * filter_njets\n",
    "    \n",
    "    return x[filter_idx]\n",
    "\n",
    "for key, set in sets.items():\n",
    "    print('-----------------loading %s-----------------' % key)\n",
    "\n",
    "    file = set['file']\n",
    "    hdf5_file = h5py.File(file, 'r')\n",
    "    \n",
    "    data = hdf5_file['data']\n",
    "    n_tot = hdf5_file['n_tot'][()]\n",
    "    n_tup = data.shape[0]\n",
    "    \n",
    "    if key == 'data':\n",
    "        x = data[()]\n",
    "    else:\n",
    "        n_tot_target = lum * set['xsec'] * set['K']\n",
    "        n_tup_target = int(n_tot_target/n_tot * n_tup)\n",
    "        \n",
    "        print('n_tup        = %d' % n_tup)\n",
    "        print('n_tup_target = %d' % n_tup_target)\n",
    "        if(n_tup < n_tup_target):\n",
    "            print('***********WARNING***********: not enough samples available')\n",
    "            \n",
    "        x = data[0:n_tup_target]\n",
    "    \n",
    "    # run preselection\n",
    "    # x = pre_select(x)\n",
    "    \n",
    "    sets[key]['x_pre'] = x\n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load data into memory\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy1jets: (403790, 23)\n",
      "dy2jets: (148215, 23)\n",
      "dy3jets: (44099, 23)\n",
      "dy4jets: (13323, 23)\n",
      "w1jets: (1682703, 23)\n",
      "w2jets: (705553, 23)\n",
      "w3jets: (167878, 23)\n",
      "ttbar: (128462, 23)\n",
      "data: (7711955, 23)\n"
     ]
    }
   ],
   "source": [
    "for key, set in sets.items():\n",
    "    print('%s: %s' % (key, set['x_pre'].shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% print shapes\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cont_bins = 25\n",
    "hist_settings = {}\n",
    "hist_settings['HT'] = {'symbol': 'Jets-$p_T$ scalar sum $H_T$ [GeV]', 'range': (0, 2000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['mass_jet'] = {'symbol': 'Jets Mass $M_J$ [GeV]', 'range': (0, 3000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_jet'] = {'symbol': 'Number of jets $N_J$', 'range': (0, 15), 'yscale': 'log', 'int': True, 'bin_size': 1}\n",
    "hist_settings['n_bjet'] = {'symbol': 'Number of b-tagged jets $N_b$', 'range': (0, 6), 'yscale': 'log', 'int': True, 'bin_size': 1}\n",
    "hist_settings['lep_pt'] = {'range': (20, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_eta'] = {'range': (-2.5, 2.5), 'yscale': 'linear', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_charge'] = {'range': (-1, 1), 'yscale': 'linear', 'int': True}\n",
    "hist_settings['lep_iso_ch'] = {'range': (0, 0.1), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_iso_neu'] = {'range': (0, 0.1), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['lep_iso_gamma'] = {'range': (0, 0.1), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['MET'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['METo'] = {'range': (-100, 100), 'yscale': 'linear', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['METp'] = {'range': (-100, 100), 'yscale': 'linear', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['MT'] = {'range': (0, 200), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_mu'] = {'range': (0, 15), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['pt_mu'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['mass_mu'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_ele'] = {'range': (0, 15), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['pt_ele'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['mass_ele'] = {'range': (0, 1000), 'yscale': 'log', 'bins': cont_bins, 'int': False}\n",
    "hist_settings['n_neu'] = {'range': (0, 400), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['n_ch'] = {'range': (0, 1000), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "hist_settings['n_photon'] = {'range': (0, 1000), 'yscale': 'linear', 'int': True, 'bin_size': 1}\n",
    "\n",
    "def build_hists(x, selection_functions):\n",
    "    hist_builder_arr = [HistogramBuilder(hist_settings) for f in selection_functions]\n",
    "    \n",
    "    x_f = x\n",
    "    for i, f in enumerate(selection_functions):\n",
    "        x_f = f(x_f)\n",
    "        hist_builder_arr[i].add_data(x_f)\n",
    "      \n",
    "    return [builder.get_histogram_data() for builder in hist_builder_arr]\n",
    "\n",
    "hist_cut_proc_dict = {}\n",
    "\n",
    "def build_all_hists(cut_functions, cut_names, proc_list=None):\n",
    "    if proc_list is None:\n",
    "        proc_list = sets.keys()\n",
    "    \n",
    "    for proc in proc_list:\n",
    "        set = sets[proc]\n",
    "        print('building hist for %s' % proc)\n",
    "    \n",
    "        # build hists\n",
    "        hists = build_hists(set['x_pre'], cut_functions)\n",
    "        \n",
    "        # add hists to dict\n",
    "        cut_name = 'pre'\n",
    "        for i in range(len(hists)):\n",
    "            cut_name += '-' + cut_names[i]\n",
    "            \n",
    "            if cut_name not in hist_cut_proc_dict:\n",
    "                hist_cut_proc_dict[cut_name] = {}\n",
    "                \n",
    "            hist_cut_proc_dict[cut_name][proc] = hists[i]\n",
    "            \n",
    "def build_anomaly_score_select(thres_target):\n",
    "    def anomaly_score_select(x, thres=thres_target, score_type='l1'):\n",
    "        x_transformed = preprocessor.transform(x)\n",
    "        scores = ad.get_anomaly_scores(x_transformed, type=score_type)  \n",
    "        anomaly_idx = scores > thres\n",
    "        return x[anomaly_idx]\n",
    "    return anomaly_score_select\n",
    "\n",
    "def build_anomaly_q_select(q_target):\n",
    "    def anomaly_q_select(x, q=q_target, score_type='l1'):\n",
    "        x_transformed = preprocessor.transform(x)\n",
    "        scores = ad.get_anomaly_scores(x_transformed, type=score_type)  \n",
    "        thres = np.quantile(scores, 1 - q)\n",
    "        anomaly_idx = scores > thres\n",
    "        return x[anomaly_idx]\n",
    "    return anomaly_q_select"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% define hist builder functions\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------building pre----------------------------\n",
      "building hist for dy1jets\n",
      "building hist for dy2jets\n",
      "building hist for dy3jets\n",
      "building hist for dy4jets\n",
      "building hist for w1jets\n",
      "building hist for w2jets\n",
      "building hist for w3jets\n",
      "building hist for ttbar\n",
      "building hist for data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------building pre----------------------------')\n",
    "\n",
    "def id_select(x):\n",
    "    return x\n",
    "\n",
    "build_all_hists([id_select], [''])\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% build pre\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------building anoscore----------------------------\n",
      "building hist for dy1jets\n",
      "building hist for dy2jets\n",
      "building hist for dy3jets\n",
      "building hist for dy4jets\n",
      "building hist for w1jets\n",
      "building hist for w2jets\n",
      "building hist for w3jets\n",
      "building hist for ttbar\n",
      "building hist for data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------building anoscore----------------------------')\n",
    "\n",
    "thres = 20\n",
    "build_all_hists([build_anomaly_score_select(thres)], ['anoscore'])\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% build anoscore\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1jets: 1682703 (0.510835)\n",
      "w2jets: 705553 (0.214192)\n",
      "w3jets: 167878 (0.050964)\n",
      "dy1jets: 403790 (0.122583)\n",
      "dy2jets: 148215 (0.044995)\n",
      "dy3jets: 44099 (0.013388)\n",
      "dy4jets: 13323 (0.004045)\n",
      "ttbar: 128462 (0.038999)\n",
      "--------------------------------------\n",
      "n_tup (mc):   3294023\n",
      "n_tup (data): 7711955\n"
     ]
    }
   ],
   "source": [
    "sum_n_pre = 0\n",
    "sum_n_ano = 0\n",
    "for proc in bs_proc_list:\n",
    "    sum_n_pre += hist_cut_proc_dict['pre-'][proc]['HT'].n\n",
    "    sum_n_ano += hist_cut_proc_dict['pre-anoscore'][proc]['HT'].n\n",
    "    \n",
    "for proc in bs_proc_list:\n",
    "    n = hist_cut_proc_dict['pre-'][proc]['HT'].n\n",
    "    print('%s: %d (%f)'%(proc, n, n/sum_n_pre))\n",
    "\n",
    "print('--------------------------------------')\n",
    "print('n_tup (mc):   %d' % sum_n_pre)\n",
    "print('n_tup (data): %d' % hist_cut_proc_dict['pre-']['data']['HT'].n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% confirm normalization\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------building ano_q_b----------------------------\n",
      "target thres = 17\n",
      "building hist for w1jets\n",
      "building hist for w2jets\n",
      "building hist for w3jets\n",
      "building hist for dy1jets\n",
      "building hist for dy2jets\n",
      "building hist for dy3jets\n",
      "building hist for dy4jets\n",
      "building hist for data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------building ano_q_b----------------------------')\n",
    "\n",
    "target_q = 1000e-6\n",
    "\n",
    "# compute threshold for b-processes to achive target_q\n",
    "b_scores = np.empty(0)\n",
    "for proc in b_proc_list:\n",
    "    x = sets[proc]['x_pre']\n",
    "    x_transformed = preprocessor.transform(x)\n",
    "    scores = ad.get_anomaly_scores(x_transformed, type='l1')\n",
    "    b_scores = np.concatenate([b_scores, scores])\n",
    "thres = np.quantile(b_scores, 1 - target_q)\n",
    "print('target thres = %d' % thres)\n",
    "\n",
    "build_all_hists([build_anomaly_score_select(thres)], ['ano_q_b'], proc_list=b_proc_list)\n",
    "build_all_hists([build_anomaly_q_select(target_q)], ['ano_q_b'], proc_list=['data'])\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% build ano_ppm to match background\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------building ano_q_bs----------------------------\n",
      "target thres = 21\n",
      "building hist for w1jets\n",
      "building hist for w2jets\n",
      "building hist for w3jets\n",
      "building hist for dy1jets\n",
      "building hist for dy2jets\n",
      "building hist for dy3jets\n",
      "building hist for dy4jets\n",
      "building hist for ttbar\n",
      "building hist for data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------building ano_q_bs----------------------------')\n",
    "\n",
    "target_q = 1000e-6\n",
    "\n",
    "def post_select(x):\n",
    "    filter_bjets =  x[:,3] > 1\n",
    "    filter_njets = x[:,2] > 5\n",
    "    filter_idx = filter_bjets * filter_njets\n",
    "    \n",
    "    return x[filter_idx]\n",
    "\n",
    "# compute threshold for b-processes to achive target_q\n",
    "bs_scores = np.empty(0)\n",
    "for proc in bs_proc_list:\n",
    "    x = sets[proc]['x_pre']\n",
    "    x_transformed = preprocessor.transform(x)\n",
    "    scores = ad.get_anomaly_scores(x_transformed, type='l1')\n",
    "    bs_scores = np.concatenate([bs_scores, scores])\n",
    "thres = np.quantile(bs_scores, 1 - target_q)\n",
    "print('target thres = %d' % thres)\n",
    "\n",
    "build_all_hists([build_anomaly_score_select(thres), post_select], ['ano_q_bs', 'pos'], proc_list=bs_proc_list)\n",
    "build_all_hists([build_anomaly_q_select(target_q), post_select], ['ano_q_bs', 'pos'], proc_list=['data'])\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% build ano_ppm to match background + signal\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------pre----------------------\n",
      "W      events: 2556134 (1000000ppm)\n",
      "DY     events: 609427 (1000000ppm)\n",
      "ttbar  events: 128462 (1000000ppm)\n",
      "b      events: 3165561 (1000000ppm)\n",
      "bs     events: 3294023 (1000000ppm)\n",
      "data   events: 7711955 (1000000ppm)\n",
      "---------------------pre-anoscore---------------------\n",
      "W      events: 1405 (   549ppm)\n",
      "DY     events: 713 (  1169ppm)\n",
      "ttbar  events: 1799 ( 14004ppm)\n",
      "b      events: 2118 (   669ppm)\n",
      "bs     events: 3917 (  1189ppm)\n",
      "data   events: 7368 (   955ppm)\n",
      "---------------------pre-ano_q_b---------------------\n",
      "W      events: 2098 (   820ppm)\n",
      "DY     events: 1068 (  1752ppm)\n",
      "b      events: 3166 (  1000ppm)\n",
      "data   events: 7712 (  1000ppm)\n",
      "---------------------pre-ano_q_bs---------------------\n",
      "W      events: 1185 (   463ppm)\n",
      "DY     events: 600 (   984ppm)\n",
      "ttbar  events: 1510 ( 11754ppm)\n",
      "b      events: 1785 (   563ppm)\n",
      "bs     events: 3295 (  1000ppm)\n",
      "data   events: 7712 (  1000ppm)\n",
      "---------------------pre-ano_q_bs-pos---------------------\n",
      "W      events: 19 (     7ppm)\n",
      "DY     events: 6 (     9ppm)\n",
      "ttbar  events: 497 (  3868ppm)\n",
      "b      events: 25 (     7ppm)\n",
      "bs     events: 522 (   158ppm)\n",
      "data   events: 497 (    64ppm)\n"
     ]
    }
   ],
   "source": [
    "for cut, hist_proc_dict in hist_cut_proc_dict.items():  \n",
    "    # sum W\n",
    "    hist_W = sum_hists([hist_proc_dict[proc] for proc in W_proc_list])\n",
    "    hist_proc_dict['W'] = hist_W\n",
    "    \n",
    "    # sum DY\n",
    "    hist_DY = sum_hists([hist_proc_dict[proc] for proc in DY_proc_list])\n",
    "    hist_proc_dict['DY'] = hist_DY\n",
    "    \n",
    "    #sum background\n",
    "    hist_b = sum_hists([hist_proc_dict[proc] for proc in b_proc_list])\n",
    "    hist_proc_dict['b'] = hist_b\n",
    "    \n",
    "    if cut == 'pre-ano_q_b':\n",
    "        continue\n",
    "        \n",
    "    #sum background + signal\n",
    "    hist_bs = sum_hists([hist_proc_dict[proc] for proc in bs_proc_list])\n",
    "    hist_proc_dict['bs'] = hist_bs\n",
    "\n",
    "# print event numbers\n",
    "for cut, hist_proc_dict in hist_cut_proc_dict.items():  \n",
    "    print('---------------------%s---------------------' % cut)\n",
    "    for proc in ['W', 'DY', 'ttbar', 'b', 'bs', 'data']:\n",
    "        if proc not in hist_proc_dict:\n",
    "            continue\n",
    "        \n",
    "        hist_proc = hist_proc_dict[proc]\n",
    "        n = hist_proc['HT'].n\n",
    "        # print('%s total events:\\t %d' %(proc, n))\n",
    "        print('{:6} events: {} ({:6d}ppm)'.format(proc, n, int(n/hist_cut_proc_dict['pre-'][proc]['HT'].n*1e6)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% sum sub processes W, DY, background, background + signal\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "pickle.dump(hist_cut_proc_dict, open('output/plot_data.pkl', 'wb'))\n",
    "pickle.dump(hist_settings, open('output/hist_settings.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% export data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}